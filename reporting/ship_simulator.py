import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import random
import yaml
import json
import sys
from .transformer import aggregate_logs
from .uploader import upload_file, file_checksum
from .health_rules import compute_health

# This script is meant to simulate the output of daily aggregations made by the ships.
# Said data is manually validated by ship captains and sent asynchronously.
# Usually, during the evening on each captain's current planet....
# I did not simulate timezones.

# In-universe, loads of data would be sent to the ship via telemetry and other IoT devices,
# which are quite common in the Pikmin universe basaed on how all devices communicate.
# Likely, a process analogous to MQTT could be happening.
# Simulating all the data from a pikmin gameplay session would take a fair amount of time,
# all for little architectural difference.
# So for these metrics, I just built the layer HQ would care about : the report.

# Some boilerplate ship_state metrics were generated by LLM (radiation, cargo intensity)
# I feel like they add to the realism, so I kept them.

# The actual real time telemetry layer differs in that it sends more technical detail,
# And is aimed at ship technicians. This one is just for business to be able to follow its ships.
# This is why it will possess its own layer.


def generate_report(state=None, mission_id=None):
    """
    Generates and uploads the captain's daily manifest report.
    If 'state' is provided, it replaces random ship_state generation.
    """

    # CLI arg parsing fallback (manual mode)
    if not mission_id:
        for arg in sys.argv:
            if arg.startswith("--missionid="):
                mission_id = arg.split("=", 1)[1].strip()
                break
    if not mission_id:
        mission_id = f"{random.randint(1000,9999)}"

    # Load MinIO config
    with open("config.yaml") as f:
        cfg = yaml.safe_load(f)

    # Date logic (+1000 years for lore)
    now = datetime.now()
    today = now.replace(year=now.year + 1000, hour=0, minute=0, second=0, microsecond=0)
    date_tag = today.strftime("%Y%m%d")
    date_iso = today.strftime("%Y-%m-%d")

    # Prepare folders
    RAW_PATH = Path("data/raw_logs")
    EXPORT_PATH = Path("data/exports")
    RAW_PATH.mkdir(parents=True, exist_ok=True)
    EXPORT_PATH.mkdir(parents=True, exist_ok=True)

    # === Cargo catalog (same as before) ===
    items = {
        "Sunseed Berry": 170, "Anxious Sprout": 80, "Flame of Tomorrow": 100,
        "Professional Noisemaker": 280, "Dream Architect": 1000, "Conifer Spire": 130,
        "Crystal King": 1200, "Lustrous Element": 150, "Remembered Old Buddy": 230,
        "Stone of Glory": 300, "Pileated Snagret Beak": 450, "Spiny Alien Trap": 220,
        "Essence of Despair": 90, "Mirrored Stage": 320, "Infernal Vegetation": 70,
        "Paradoxical Enigma": 650, "Aluminum Crates": 50, "Processed Fuel Cells": 110,
        "Frozen Food Containers": 75, "Industrial Lubricants": 95,
        "Consumer Electronics Pallet": 180, "Agricultural Seeds": 60, "Machinery Parts": 140,
    }

    def random_time_within_day(base_date: datetime) -> datetime:
        """Generate a random timestamp between 08:00 and 17:00 for the given day."""
        date = base_date.replace(hour=0, minute=0, second=0, microsecond=0)
        start = date.replace(hour=8)
        end = date.replace(hour=17)
        delta = end - start
        return start + timedelta(seconds=random.randint(0, int(delta.total_seconds())))

    # === Mission log ===
    items_list = list(items.keys())
    chosen = np.random.choice(items_list, 20)
    values = [items[i] for i in chosen]
    timestamps = [random_time_within_day(today).strftime("%Y-%m-%d %H:%M:%S") for _ in range(20)]

    mission_logs = pd.DataFrame({
        "mission_id": mission_id,
        "item": chosen,
        "value": values,
        "timestamp": timestamps
    })

    # === Ship state ===
    if state:
        # âœ… Use telemetry-derived state and compute health
        health = compute_health(state)
        ship_state = {**state, **health}
    else:
        # Legacy random state generation (used only if no telemetry provided)
        pikmin_planets = {
            "Hocotate": 0,
            "PNF-404": 3.4e8,
            "Koppai": 6.8e8,
            "Ohri": 1.2e9
        }
        planet = random.choice(list(pikmin_planets.keys()))
        r = pikmin_planets[planet]

        if planet != "Hocotate":
            r *= np.random.uniform(0.9, 1.1)
            theta = np.random.uniform(-0.05, 0.05)
            phi = np.random.uniform(0, 2 * np.pi)
            x = r * np.cos(phi)
            y = r * np.sin(phi)
            z = r * np.sin(theta)
        else:
            x = y = z = 0

        fixed_time = datetime.now().replace(
            year=datetime.now().year + 1000,
            hour=18, minute=0, second=0, microsecond=0
        )

        ship_state = {
            "timestamp": fixed_time.strftime("%Y-%m-%dT%H:%M:%SZ"),
            "fuel_prc": np.random.randint(30, 100),
            "ship_condition": random.choice(["OK", "DAMAGED", "REPAIRING"]),
            "temperature_C": round(np.random.uniform(-180, 60), 1),
            "radiation_uSv": round(np.random.uniform(0.1, 10.0), 2),
            "cargo_integrity_prc": np.random.randint(80, 100),
            "coordinates": {
                "x_km": round(x, 2),
                "y_km": round(y, 2),
                "z_km": round(z, 2),
                "planet": planet
            }
        }

    # === Transform & upload ===
    mission_csv = RAW_PATH / f"mission_{mission_id}_{date_tag}.csv"
    mission_logs.to_csv(mission_csv, index=False)
    mission_pq = aggregate_logs(cfg, RAW_PATH, EXPORT_PATH, mission_id, date_tag)

    mission_bucket = cfg["minio"]["buckets"]["mission"]
    date_prefix = f"{mission_id}/{date_iso}"
    mission_key = f"{date_prefix}/mission_{mission_id}_{date_tag}.parquet"
    manifest_name = f"manifest_{mission_id}_{date_tag}.json"
    manifest_key = f"{date_prefix}/{manifest_name}"

    mission_sha = file_checksum(EXPORT_PATH / mission_pq)

    fixed_time = datetime.now().replace(
        year=datetime.now().year + 1000,
        hour=18, minute=0, second=0, microsecond=0
    )

    daily_manifest = {
        "mission_id": mission_id,
        "date": date_iso,
        "files": {"mission": mission_key},
        "checksum": {"mission": mission_sha},
        "ship_state": ship_state,
        "upload_time": fixed_time.strftime("%Y-%m-%dT%H:%M:%SZ")
    }

    manifest_path = EXPORT_PATH / manifest_name
    manifest_path.write_text(json.dumps(daily_manifest, indent=2))

    upload_file(EXPORT_PATH / mission_pq, mission_bucket, cfg, object_name=mission_key)
    upload_file(manifest_path, mission_bucket, cfg, object_name=manifest_key)

    coords = ship_state.get("coordinates", {})
    print(f"âœ… Mission {mission_id} ({today.year}) uploaded successfully; all items logged before 17:00.")
    if coords:
        print(f"ðŸ“¡ Ship: fuel {ship_state.get('fuel_prc', '?')}%, "
              f"planet: {coords.get('planet', '?')}, "
              f"coords ({coords.get('x_km', 0):.2e}, {coords.get('y_km', 0):.2e}, {coords.get('z_km', 0):.2e})")
        print(f"ðŸ’¡ Condition: {ship_state.get('ship_condition', '?')} "
              f"(health={ship_state.get('normalized_health_total', '?')})")


if __name__ == "__main__":
    generate_report()
